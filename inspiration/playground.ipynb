{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Here, we define hyper-parameters, which define how our model learns.\n",
    "Additionally, here could be other global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the decision, whether we use the gpu or cpu. Using the gpu needs torch to be compiled with cuda support! <br>\n",
    "Almost everything needs to be loaded onto the device, by using `.to(device)` on the model or other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "Here we load the data to train our model. Either use a predefined dataset like MNIST or just load your own data.<br>\n",
    "In Detail:\n",
    "- `Dataset` contains the data + labels\n",
    "- `DataLoader` contains method to load data from the Dataset in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "\troot=\"data\",\n",
    "\ttrain=True,\n",
    "\tdownload=True,\n",
    "\ttransform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "\troot=\"data\",\n",
    "\ttrain=False,\n",
    "\tdownload=True,\n",
    "\ttransform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "The actual implementation of our network. The only important method is the `forward` method, which defines how our model transforms the input data. The construtor is used to define the used methods, to make our forward method look nice and tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "\t\t\tnn.Linear(28*28, 784),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(784, 784),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(784, 10),\n",
    "\t\t\tnn.ReLU()\n",
    "\t\t)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Here we define the learning and evaluation process (during training). The learning steps are as follows:\n",
    "1. Let our model produce a prediction\n",
    "2. Calculate the loss using any loss function\n",
    "3. Calculate the gradient using backpropagation\n",
    "4. Let the optimizer do it's magic (update parameters in some way)\n",
    "5. Restore the gradient of the optimizer to zero, to avoid calculating the new gradient based on the old one\n",
    "\n",
    "The evaluation methods just does the first two steps, and returns how wrong our model is based on the test dataset. Here we wrap our code in torch.no_grad() to avoid calculating unnecessarry gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader: DataLoader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    for ibatch, (input, target) in enumerate(dataloader):\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        pred = model(input)\n",
    "        loss = loss_fn(pred, target)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if ibatch % 100 == 0:\n",
    "            loss, current = loss.item(), ibatch * batch_size + len(input)\n",
    "            # progress bar\n",
    "            width = 50\n",
    "            print(f\"\\r[{'=' * int(width * current / size)}{' ' * (width - int(width * current / size))}] {current:>5d}/{size:>5d} Loss: {loss:>7f}\", end=\"\")\n",
    "    print(f\"\\r[{'=' * width}] Done! Loss: {loss:>7f}\")\n",
    "            \n",
    "def test_loop(dataloader: DataLoader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        for input, target in dataloader:\n",
    "            input, target = input.to(device), target.to(device) \n",
    "            pred = model(input)\n",
    "            test_loss += loss_fn(pred, target).item()\n",
    "            correct += (pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the train- and eval-loops with the training data for n-epochs. Also define the loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "\tprint(f\"Epoch {t+1}\")\n",
    "\ttrain_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "\ttest_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Actually do something with the model. For this, the input needs to be exatly as the training data, so in this case we need to convert our image to grayscale, resize it to 28x28, convert it into an tensor and invert the image to make white near to 0 and black near to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(path):\n",
    "    image = Image.open(path).convert(\"L\") # Load image and convert to grayscale\n",
    "    transform = transforms.Compose([\n",
    "\t\ttransforms.Resize((28, 28)),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Lambda(lambda x: 1 - x), # Invert image, so that white is 0 and black is 1\n",
    "\t])\n",
    "    return transform(image).unsqueeze(0) # add batch dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a small prediction method, which just takes in the image as a tensor (via loadImage), transfer it onto the `device`, the model is loaded on and infer the result. Then we call softmax (not necessary, because argmax returns the highest value anyway) to normalize our logits into a vector, where all values add up to 1 and range from 0 to 1. Then we take the one with the highest probability of success via `argmax(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, image):\n",
    "\timage = image.to(device)\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tpred = nn.Softmax(dim=1)(model(image))\n",
    "\t\treturn pred.argmax(1).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loadImage(\"5.png\")\n",
    "print(pred(model, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "Here i defined some functions, that output the tensors into a human readable format. I used that, to see if my image was correctly represented as a Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = loadImage(\"5.png\").squeeze().numpy()\n",
    "for row in array:\n",
    "\t\tprint(\" \".join(f\"{pixel:.1f}\" for pixel in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show the first 10 items, e.g. image and label\n",
    "for i in range(10):\n",
    "\timage, label = test_data[i]\n",
    "\timage_array = image.squeeze().numpy()\n",
    "\tprint(label)\n",
    "\tfor row in image_array:\n",
    "\t\tprint(\" \".join(f\"{pixel:.1f}\" for pixel in row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
