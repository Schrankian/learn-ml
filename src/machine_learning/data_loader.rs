#![allow(dead_code)]
use byteorder::{BigEndian, ReadBytesExt};
use ndarray::Array2;
use rand::seq::SliceRandom;
use std::fs::File;
use std::io::Result;
use std::io::{BufReader, Read};
use image::{ImageReader, GrayImage};

/// Reads an IDX3-ubyte file and returns an ndarray of shape (num_images, height * width) with f32 values in [0, 1]
fn load_mnist_images(path: &str) -> Result<Array2<f32>> {
    let mut file = BufReader::new(File::open(path)?);

    // Read magic number
    let magic = file.read_i32::<BigEndian>()?;
    // 0x08 (data type: unsigned byte), 0x03 (3D array: images)
    if magic != 2051 {
        panic!("Invalid MNIST image file magic number: {}", magic);
    }

    // Read metadata
    let num_images = file.read_i32::<BigEndian>()? as usize;
    let num_rows = file.read_i32::<BigEndian>()? as usize;
    let num_cols = file.read_i32::<BigEndian>()? as usize;
    let image_size = num_rows * num_cols;

    // Read image data into a buffer
    let mut buffer = vec![0u8; num_images * image_size];
    file.read_exact(&mut buffer)?;

    // Convert to f32 and normalize to range [0, 1]
    // u8 ranges from 0 (black) to 255 (white)
    let float_buffer: Vec<f32> = buffer.iter().map(|&x| x as f32 / 255.0).collect();

    // Convert to ndarray with shape (num_images, height * width)
    Ok(Array2::from_shape_vec((num_images, image_size), float_buffer).unwrap())
}

/// Encodes a single usize lable into a one-hot encoded f32 vector of length 10
fn encode_one_hot(label: u8) -> Vec<f32> {
    let mut one_hot = vec![0.0; 10];
    one_hot[label as usize] = 1.0;
    one_hot
}

/// Reads an IDX1-ubyte file and returns an ndarray with one-hot encoded f32 labels (range 0-9)
fn load_mnist_labels(path: &str) -> Result<Array2<f32>> {
    let mut file = BufReader::new(File::open(path)?);

    // Read magic number
    let magic = file.read_i32::<BigEndian>()?;
    // 0x08 (data type: unsigned byte), 0x01 (1D array: labels)
    if magic != 2049 {
        panic!("Invalid MNIST label file magic number: {}", magic);
    }

    // Read metadata
    let num_labels = file.read_i32::<BigEndian>()? as usize;

    // Read label data
    let mut buffer = vec![0u8; num_labels];
    file.read_exact(&mut buffer)?;

    // Convert labels to f32
    let float_buffer: Vec<f32> = buffer
        .iter()
        .map(|&x| encode_one_hot(x))
        .flatten()
        .collect();

    // Convert to ndarray with shape (num_labels, 10)
    Ok(Array2::from_shape_vec((num_labels, 10), float_buffer).unwrap())
}

/// A simple DataLoader for the MNIST dataset <br>
/// Important note on the batch size: <br>
/// You should NOT perform multiple forward passes and accumulate the gradients <br>
/// You SHOULD however put the whole batch through the network at the SAME TIME
/// so the inputs, outputs and each layers neurons then have the shape (batch_size, num_neurons)
pub struct DataLoader {
    images: Array2<f32>,
    labels: Array2<f32>,
    batch_size: usize,
}

impl DataLoader {
    /// Create a new DataLoader from already loaded images and labels
    pub fn new(images: Array2<f32>, labels: Array2<f32>, batch_size: usize) -> Self {
        Self {
            images,
            labels,
            batch_size,
        }
    }

    /// Create a new DataLoader from a Dataset downloaded via the python pytorch library
    /// The path should point to the directory containing the files
    /// The prefix is in most cases either "train" or "t10k" for the training data and test data respectively
    pub fn from_dir(path: &str, prefix: &str, batch_size: usize) -> Result<Self> {
        let images = load_mnist_images(&format!("{}/{}-images-idx3-ubyte", path, prefix))?;
        let labels = load_mnist_labels(&format!("{}/{}-labels-idx1-ubyte", path, prefix))?;

        Ok(Self::new(images, labels, batch_size))
    }

    /// Create a new DataLoader from the paths to the images and labels files downlaoed via the python pytorch library
    pub fn from_path(images_path: &str, labels_path: &str, batch_size: usize) -> Result<Self> {
        let images = load_mnist_images(images_path)?;
        let labels = load_mnist_labels(labels_path)?;

        Ok(Self::new(images, labels, batch_size))
    }

    pub fn images(&self) -> &Array2<f32> {
        &self.images
    }

    pub fn labels(&self) -> &Array2<f32> {
        &self.labels
    }

    pub fn batch_size(&self) -> usize {
        self.batch_size
    }

    /// Returns the number of batches, which will be generated by the DataLoader
    pub fn num_batches(&self) -> usize {
        // Returns the number of batches
        // The last batch may have fewer than batch_size elements
        // So we add the batch_size -1 to the number of images and divide by batch_size (rounding up)
        (self.images.nrows() + self.batch_size - 1) / self.batch_size
    }

    /// Returns an iterator over the batches of images and labels
    /// Shapes: (batch_size, height * width), (batch_size, 10)
    /// The last batch may have fewer than batch_size elements
    /// The images and labels are owned by the iterator
    pub fn batches<'a>(
        &'a self,
        shuffle: bool,
    ) -> impl Iterator<Item = (Array2<f32>, Array2<f32>)> + 'a {
        let mut indices: Vec<usize> = (0..self.images.nrows()).collect();
        // If wanted, shuffle the indices to get random batches each epoch
        if shuffle {
            let mut rng = rand::rng();
            indices.shuffle(&mut rng);
        }

        let num_batches = self.num_batches();
        (0..num_batches).map(move |i| {
            // Get the start and end index of the current batch. If the end index is larger than the number of images, we take the last index
            let start = i * self.batch_size;
            let end = ((i + 1) * self.batch_size).min(self.images.nrows());
            // Collect the indices of the current batch
            let batch_indices = &indices[start..end];

            // Create the batch images and labels from the indices
            // j counts from 0..batch_size, k counts from 0..image_size=784/label_size=10
            // So the Array is filled with all columns from the images and labels, where the first column match the indices of the current batch (stored in batch_indices)
            let batch_images =
                Array2::from_shape_fn((batch_indices.len(), self.images.ncols()), |(j, k)| {
                    self.images[(batch_indices[j], k)]
                });
            let batch_labels =
                Array2::from_shape_fn((batch_indices.len(), self.labels.ncols()), |(j, k)| {
                    self.labels[(batch_indices[j], k)]
                });
            (batch_images, batch_labels)
        })
    }
}

/// Loads an image (currently only tested for pngs) and returns it as a 2D array with shape (1, height * width)
/// The image is already preprocessed and can be used as input for a neural network
pub fn load_image(path: &str) -> Array2<f32> {
    // Load the image
    let img = ImageReader::open(path).expect("Failed to open image").decode().expect("Failed to decode image");

    // Convert to grayscale, rotate 90 degrees and flip vertically, so the image is in the same orientation as the MNIST dataset
    let gray_img: GrayImage = img.flipv().rotate90().to_luma8();
    
    // Get image dimensions
    let (width, height) = gray_img.dimensions();
    
    // Convert to ndarray and normalize
    let mut array = Array2::<f32>::zeros((1, height as usize * width as usize));
    
    let mut min_val = 255.0;
    let mut max_val = 0.0;
    
    for (y, x, pixel) in gray_img.enumerate_pixels() {
        let value = pixel[0] as f32;
        array[[0, y as usize * width as usize + x as usize]] = value; // Flip y-axis
        
        if value < min_val {
            min_val = value;
        }
        if value > max_val {
            max_val = value;
        }
    }
    
    // Normalize: scale pixel values to range [0,1], where white is 0.0 and black is 1.0
    if max_val != min_val {
        array.mapv_inplace(|v| (max_val - v) / (max_val - min_val));
    }
    
    array
}

#[cfg(test)]
mod tests {
    use super::*;
    use ndarray::array;

    // Attention: Theses tests require the MNIST dataset to be downloaded via the python pytorch library
    const MNIST_PATH: &str = "./data/MNIST/raw";

    #[test]
    fn test_dir_loader() {
        let loader = DataLoader::from_dir(MNIST_PATH, "train", 1).unwrap();
        assert_eq!(loader.images().shape(), &[60000, 784]);
        assert_eq!(loader.labels().shape(), &[60000, 10]);
    }

    #[test]
    fn test_path_loader() {
        let images_path = format!("{}/{}-images-idx3-ubyte", MNIST_PATH, "train");
        let labels_path = format!("{}/{}-labels-idx1-ubyte", MNIST_PATH, "train");
        let loader = DataLoader::from_path(&images_path, &labels_path, 1).unwrap();
        assert_eq!(loader.images().shape(), &[60000, 784]);
        assert_eq!(loader.labels().shape(), &[60000, 10]);
    }

    #[test]
    fn test_num_batches() {
        let loader = DataLoader::new(
            array![[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]],
            array![[1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],
            1,
        );
        assert_eq!(loader.num_batches(), 3);
    }

    #[test]
    fn test_batches_iterator() {
        let loader = DataLoader::new(
            array![[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]],
            array![[1.0, 0.0], [0.0, 1.0], [1.0, 0.0]],
            1,
        );
        let mut batches = loader.batches(false);
        assert_eq!(
            batches.next(),
            Some((array![[1.0, 2.0]], array![[1.0, 0.0]]))
        );
        assert_eq!(
            batches.next(),
            Some((array![[3.0, 4.0]], array![[0.0, 1.0]]))
        );
        assert_eq!(
            batches.next(),
            Some((array![[5.0, 6.0]], array![[1.0, 0.0]]))
        );
        assert_eq!(batches.next(), None);
    }
}
